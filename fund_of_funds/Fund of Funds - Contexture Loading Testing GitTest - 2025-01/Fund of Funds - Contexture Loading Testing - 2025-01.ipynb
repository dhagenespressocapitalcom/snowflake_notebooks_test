{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "4bnaomzhinzqtjt5fape",
   "authorId": "114522270066",
   "authorName": "DHAGENESPRESSOCAPITALCOM",
   "authorEmail": "dhagen@espressocapital.com",
   "sessionId": "4396e53b-7238-434f-95b2-2d1ac53705ba",
   "lastEditTime": 1739903775199
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "create_dest_tables",
    "collapsed": false
   },
   "source": "-- create target tables\nCREATE OR REPLACE TABLE raw.contexture_fof.raw_metadata (\n    fund STRING,\n    document_type STRING,\n    document_date STRING,\n    source_filename STRING\n);\n\nCREATE OR REPLACE TABLE raw.contexture_fof.raw_nvestments (\n    company_name STRING,\n    inv_type STRING,\n    date STRING,\n    shares integer,\n    cost numeric(21,2),\n    fair_value numeric(21,2),\n    gain_loss numeric(21,2),\n    cost_per_share numeric(21,2),\n    fair_value_per_share numeric(21,2)\n);\n\nCREATE OR REPLACE TABLE raw.contexture_fof.raw_statement_of_operations (\n    type integer,\n    total STRING\n);\n\n-- Remove for now.\nDROP TABLE RAW.CONTEXTURE_FOF.RAW_METADATA;\nDROP TABLE RAW.CONTEXTURE_FOF.RAW_NVESTMENTS;\nDROP TABLE RAW.CONTEXTURE_FOF.RAW_STATEMENT_OF_OPERATIONS;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9eb661bd-7caa-46be-ab4c-713fb3f21e77",
   "metadata": {
    "language": "sql",
    "name": "create_stage_s3",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- create a stage to S3.  No filetype defined for this one.\nCREATE OR REPLACE STAGE s3_contexture_bucket\n-- URL = 's3://ec-flowpoint-bucket/test_folder/'\nURL = 's3://ec-contexture-portal-bucket/'\nCREDENTIALS = (AWS_KEY_ID = '--nothing--' AWS_SECRET_KEY = '--nothing--')\nDIRECTORY = ( ENABLE = true );\n--FILE_FORMAT = (TYPE = 'NONE')\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef709110-3420-4bb7-a434-608d687ddd55",
   "metadata": {
    "language": "sql",
    "name": "list_stage_contents",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "LIST @raw.contexture_fof.s3_contexture_bucket;\n-- LIST CC_QUICKSTART_CORTEX_SEARCH_DOCS.DATA.DOCS;\n\n-- SELECT $1 FROM @s3_contexture_bucket;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8795ca9-0f05-442c-942f-2a195248a3dc",
   "metadata": {
    "language": "python",
    "name": "copy_excel_data",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\nimport boto3\nfrom io import BytesIO\nfrom snowflake.core import Root\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col\n\n# Create Snowpark session\nsession = get_active_session()\n\nfiles_in_stage = session.sql(\"LIST @s3_contexture_bucket\").collect()\n\nfor file in files_in_stage:\n    print(f\"file: {file}and key file[file_key]\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "db2dc309-4038-4a60-9d6b-6a25b9a40c03",
   "metadata": {
    "language": "sql",
    "name": "create_landing_db"
   },
   "outputs": [],
   "source": "-- USE ROLE ACCOUNTADMIN;\n-- CREATE DATABASE ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6d1bf68-c5fe-4d12-8148-b83bd482af3b",
   "metadata": {
    "language": "sql",
    "name": "create_chunker_udf",
    "collapsed": false
   },
   "outputs": [],
   "source": "--\n-- Creates a data chunker so that we can load the contents of files (pdf) into a database so that we can use it for AI purposes.\n-- \ncreate or replace function analytics.functions.text_chunker(pdf_text string)\nreturns table (chunk varchar)\nlanguage python\nruntime_version = '3.9'\nhandler = 'text_chunker'\npackages = ('snowflake-snowpark-python', 'langchain')\nas\n$$\nfrom snowflake.snowpark.types import StringType, StructField, StructType\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nimport pandas as pd\n\nclass text_chunker:\n\n    def process(self, pdf_text: str):\n        \n        text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size = 1512, #Adjust this as you see fit\n            chunk_overlap  = 256, #This let's text have some form of overlap. Useful for keeping chunks contextual\n            length_function = len\n        )\n    \n        chunks = text_splitter.split_text(pdf_text)\n        df = pd.DataFrame(chunks, columns=['chunks'])\n        \n        yield from df.itertuples(index=False, name=None)\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ee252c1-cfb4-4a15-9572-7440072bbea3",
   "metadata": {
    "language": "sql",
    "name": "query_pdfs_on_s3",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Big question here ... does this work in DBT?\n-- attach this to an insert statement or do it with dbt.\n--\nselect \n    name,\n    relative_path, \n    size as file_size,\n    file_url, \n    build_scoped_file_url(@raw.contexture_fof.s3_contexture_bucket, relative_path) as scoped_file_url,\n    last_modified as file_last_modified,\n    md5 as file_md5,\n    func.chunk as chunk\nfrom \n    directory(@raw.contexture_fof.s3_contexture_bucket),\n    TABLE(\n        analytics.functions.text_chunker (\n            to_varchar(\n                snowflake.cortex.parse_document(\n                    @raw.contexture_fof.s3_contexture_bucket, \n                    relative_path, \n                    {'mode': 'LAYOUT'}\n                )\n            )\n        )\n    ) as func\n where relative_path ilike '%.pdf'\n  -- where relative_path='Cortical Ventures Fund I LP - Espresso Credit US LP - statement - Q3 2024.pdf'\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7a7f1e7-4075-493b-841d-2e9d950a5061",
   "metadata": {
    "language": "sql",
    "name": "cell1",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Big question here ... does this work in DBT?\n-- attach this to an insert statement or do it with dbt.\n--\nselect \n    *\n    -- func.chunk as chunk\nfrom \n    directory(@raw.contexture_fof.s3_contexture_bucket),\n    -- TABLE(\n    --     analytics.functions.text_chunker (\n    --         to_varchar(\n    --             snowflake.cortex.parse_document(\n    --                 @raw.contexture_fof.s3_contexture_bucket, \n    --                 relative_path, \n    --                 {'mode': 'LAYOUT'}\n    --             )\n    --         )\n    --     )\n    -- ) as func\n where relative_path ilike '%.pdf'\n  -- where relative_path='Cortical Ventures Fund I LP - Espresso Credit US LP - statement - Q3 2024.pdf'\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "260be218-509a-4d02-9cc3-5ceb9092e129",
   "metadata": {
    "language": "sql",
    "name": "reset_chunks_table",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- alter table staging.dbt_dhagen.int_fund_of_funds__contexture_pdf_chunks rename to staging.dbt_dhagen.int_fund_of_funds__pdf_chunks;\n-- select * from staging.dbt_dhagen.int_fund_of_funds__pdf_chunks;\n\n-- create table staging.unstructured.int_fund_of_funds__pdf_chunks as \n-- select * from staging.dbt_dhagen.int_fund_of_funds__pdf_chunks;\n\ndrop table STAGING.UNSTRUCTURED.INT_FUND_OF_FUNDS__CONTEXTURE_PDF_CHUNKS;",
   "execution_count": null
  }
 ]
}